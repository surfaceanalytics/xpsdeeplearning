{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"talos_optimization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vt5hanGL4WpD"},"source":["# Hyperparameter optimization of a CNN for XPS data in Keras using Talos"]},{"cell_type":"markdown","metadata":{"id":"uTjEnuR-LwEo"},"source":["In this notebook, we will search the hyperparameter space of a convolutional network for photoemission spectra made up of linear combinations of single reference spectra using Talos (https://autonomio.github.io/docs_talos/)"]},{"cell_type":"markdown","metadata":{"id":"u6EVGrGFLwEr"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"dU2aEkqdLwE_"},"source":["### Mount google drive, change working directory"]},{"cell_type":"code","metadata":{"id":"5iL11_yXLwFB"},"source":["# Mount drive\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","\n","# Change working path\n","os.chdir('/content/drive/My Drive/deepxps')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rC3yXYXaLwEt"},"source":["### Install packages and import modules"]},{"cell_type":"code","metadata":{"id":"s4MxYB_b33V9"},"source":["%%capture\n","# Install packages\n","#!pip install git+https://github.com/autonomio/talos@1.0\n","\n","# Using forked Talos v1.0\n","!pip install git+git://github.com/lukaspie/talos.git@1.0#egg=talos \n","\n","# =============================================================================\n","# If forked repo is present on Google Drive.\n","# os.chdir('/content/drive/My Drive/app/talos')\n","# ! git checkout 1.0\n","# !pip install .\n","# os.chdir('/content/drive/My Drive/app')\n","# !pwd\n","# =============================================================================\n","\n","!pip install python-docx\n","!pip install tensorflow==2.3.0 as tf\n","\n","# Import standard modules and magic commands\n","import tensorflow as tf\n","import datetime\n","import numpy as np\n","import pytz\n","import importlib\n","\n","# Magic commands\n","%matplotlib inline\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","# Disable tf warnings\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gh_mK7xmWMCc"},"source":["### Check TensorFlow version"]},{"cell_type":"code","metadata":{"id":"OSBP_xNM_Ikz"},"source":["try:\n","    tf.__version__\n","except:\n","    tf.VERSION"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-qQx0QfuLwFQ"},"source":["### Load custom modules"]},{"cell_type":"code","metadata":{"id":"SfLJzbL04VZ8"},"source":["try:\n","    importlib.reload(classifier)\n","    importlib.reload(opt)\n","    importlib.reload(clfutils)\n","    print('Modules were reloaded.')\n","except:\n","    import xpsdeeplearning.network.classifier as classifier\n","    import xpsdeeplearning.network.optimization as opt\n","    import xpsdeeplearning.network.utils as clfutils\n","    print('Modules were loaded.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j7M70DZczykg"},"source":["### Set up the parameters & folder structure\n","\n"]},{"cell_type":"code","metadata":{"id":"6uMjOpdzVoO3"},"source":["seed = 501\n","np.random.seed(seed)\n","time = datetime.datetime.now().astimezone(pytz.timezone('Europe/Berlin')).strftime(\"%Y%m%d_%Hh%Mm\")\n","exp_name = 'Fe_4_classes_variable_linear_comb_gas_phase_combined_data_talos'\n","\n","hyperopt = opt.Hyperoptimization(time = time,\n","                                 exp_name = exp_name)\n","hyperopt.initialize_clf(task = 'regression',\n","                        intensity_only = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0wkRVOuLwFy"},"source":["### Load and inspect the data"]},{"cell_type":"code","metadata":{"id":"mDER1Z_QV4Wk"},"source":["input_filepath = r'/content/drive/My Drive/deepxps/datasets/20210222_Fe_linear_combination_small_gas_phase.h5'\n","train_test_split = 0.2\n","train_val_split = 0.2\n","no_of_examples = 2000\n","\n","X_train, X_val, X_test, y_train, y_val, y_test,\\\n","    aug_values_train, aug_values_val, aug_values_test =\\\n","        hyperopt.clf.load_data_preprocess(input_filepath = input_filepath,\n","                                          no_of_examples = no_of_examples,\n","                                          train_test_split = train_test_split,\n","                                          train_val_split = train_val_split)\n","               \n","# Check how the examples are distributed across the classes.\n","class_distribution = hyperopt.clf.datahandler.check_class_distribution(hyperopt.clf.task)\n","hyperopt.clf.plot_class_distribution()\n","hyperopt.clf.plot_random(no_of_spectra = 10, dataset = 'train')  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GZab5zUwYJlV"},"source":["## Model design"]},{"cell_type":"code","metadata":{"id":"pyxJ9_qh5awz"},"source":["try:\n","    importlib.reload(models)\n","    print('Models module was reloaded.')\n","except:\n","    import xpsdeeplearning.network.models as models\n","    print('Models module was loaded.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UzVHVffNEu3G"},"source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, Lambda\n","from tensorflow.keras.layers import Conv1D\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import AveragePooling1D, MaxPooling1D\n","from tensorflow.keras.layers import LayerNormalization\n","from tensorflow.python.keras import backend as K\n","\n","class CustomCNNTalos(models.EmptyModel):\n","    def __init__(self, inputshape, num_classes, params):      \n","        input_1 = Input(shape = inputshape)\n","                \n","        conv_1_short = Conv1D(\n","            int(params['conv_1_short_filters']),\n","            int(params['conv_1_short_kernel_size']),\n","            padding = 'same',\n","            activation = str(params['conv_1_short_activation']))(input_1)\n","        conv_1_medium = Conv1D(\n","            int(c),\n","            int(params['conv_1_medium_kernel_size']),\n","            padding = 'same',\n","            activation = str(params['conv_1_medium_activation']))(input_1)\n","        conv_1_long = Conv1D(\n","            int(params['conv_1_long_filters']),\n","            int(params['conv_1_long_kernel_size']),\n","            padding = 'same',\n","            activation = str(params['conv_1_long_activation']))(input_1)\n","        sublayers = [conv_1_short, conv_1_medium, conv_1_long]\n","        merged_sublayers = concatenate(sublayers)\n","\n","        conv_2 = Conv1D(\n","            int(params['conv_2_filters']),\n","            int(params['conv_2_kernel_size']),\n","            padding = 'same',\n","            activation = str(params['conv_2_activation']))(merged_sublayers)\n","        conv_3 = Conv1D(\n","            int(params['conv_3_filters']),\n","            int(params['conv_3_kernel_size']),\n","            padding = 'same',\n","            activation = str(params['conv_3_activation']))(conv_2)\n","        average_pool_1 = AveragePooling1D()(conv_3)\n","        flatten_1 = Flatten()(average_pool_1)\n","        drop_1 = Dropout(float(params['drop_1_rate']))(flatten_1)\n","        dense_1 = Dense(\n","            int(params['dense_1_units']),\n","            activation = str(params['dense_1_activation']))(drop_1)\n","        dense_2 = Dense(num_classes, activation = 'sigmoid')(dense_1)\n","        \n","        output = Lambda(lambda x: x/tf.reshape(K.sum(x, axis=-1),(-1,1)),\n","                        name = 'normalization')(dense_2)\n","\n","        no_of_inputs = len(sublayers)\n","\n","        super(CustomCNNTalos, self).__init__(inputs = input_1,\n","                                             outputs = output,\n","                                             inputshape = inputshape,\n","                                             num_classes = num_classes,\n","                                             no_of_inputs = no_of_inputs,\n","                                             name = 'Custom_CNN_Talos')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JeHmsbXvOmS6"},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n","\n","init_params = {'conv_1_short_filters' : 12,\n","               'conv_1_short_kernel_size' : 5,\n","               'conv_1_short_activation' : 'relu',\n","               'conv_1_medium_filters' : 12,\n","               'conv_1_medium_kernel_size' : 10,\n","               'conv_1_medium_activation' : 'relu',\n","               'conv_1_long_filters' : 12,\n","               'conv_1_long_kernel_size' : 15,\n","               'conv_1_long_activation' : 'relu',\n","               'conv_2_filters' : 10,\n","               'conv_2_kernel_size' : 5,\n","               'conv_2_activation' : 'relu',\n","               'conv_3_filters' : 10,\n","               'conv_3_kernel_size' : 5,\n","               'conv_3_activation' : 'relu',\n","               'drop_1_rate' : 0.2,\n","               'dense_1_units' : 4000,\n","               'dense_1_activation' : 'relu',\n","               'optimizer' : Adam,\n","               'learning_rate': 1e-05,\n","               'loss_function' : MeanAbsoluteError\n","              }\n","\n","hyperopt.clf.model = CustomCNNTalos(hyperopt.clf.datahandler.input_shape,\n","                                    hyperopt.clf.datahandler.num_classes,\n","                                    init_params)\n","\n","# Compile model with loss function and optimizer from parameter dictionary.\n","hyperopt.clf.model.compile(\n","    loss = init_params['loss_function'](),\n","    optimizer = init_params['optimizer'](init_params['learning_rate']))\n","\n","# Plot summary and save model plot.\n","hyperopt.clf.summary()\n","hyperopt.clf.save_and_print_model_image()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4SWUHsG8LV49"},"source":["## Hyperparameter optimization"]},{"cell_type":"markdown","metadata":{"id":"fvoY9t26LPuX"},"source":["### Parameter Scan"]},{"cell_type":"code","metadata":{"id":"KHwpFDcHXxd5"},"source":["opt_params = {'conv_1_short_filters' : [6, 12, 18],\n","               'conv_1_short_kernel_size' : [3, 5, 7],\n","               'conv_1_short_activation' : ['relu'],\n","               'conv_1_medium_filters' : [6, 12, 18],\n","               'conv_1_medium_kernel_size' : [8, 10, 12],\n","                'conv_1_medium_activation' : ['relu'],\n","               'conv_1_long_filters' : [6, 12, 18],\n","               'conv_1_long_kernel_size' : [13 ,15, 17],\n","               'conv_1_long_activation' : ['relu'],\n","               'conv_2_filters' : [5, 10, 15],\n","               'conv_2_kernel_size' : [3, 5, 7],\n","               'conv_2_activation' : ['relu'],\n","               'conv_3_filters' : [5, 10, 15],\n","               'conv_3_kernel_size' : [3, 5, 7],\n","               'conv_3_activation' : ['relu'],\n","               'drop_1_rate' : [0.1, 0.2],\n","               'dense_1_units' : [2000, 4000, 6000],\n","               'dense_1_activation' : ['relu'],\n","               'optimizer' : [Adam],\n","               'learning_rate': [1e-05, 3e-04, 1e-04],\n","               'loss_function' : [MeanAbsoluteError],\n","               'epochs' : [50],\n","               'batch_size' : [16, 32]\n","                }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ea9sBx9gXsNu"},"source":["test_params = {'conv_1_short_filters' : [12],\n","               'conv_1_short_kernel_size' : [5],\n","               'conv_1_short_activation' : ['relu'],\n","               'conv_1_medium_filters' : [12],\n","               'conv_1_medium_kernel_size' : [10],\n","                'conv_1_medium_activation' : ['relu'],\n","               'conv_1_long_filters' : [12],\n","               'conv_1_long_kernel_size' : [15],\n","               'conv_1_long_activation' : ['relu'],\n","               'conv_2_filters' : [10],\n","               'conv_2_kernel_size' : [5],\n","               'conv_2_activation' : ['relu'],\n","               'conv_3_filters' : [10],\n","               'conv_3_kernel_size' : [5],\n","               'conv_3_activation' : ['relu'],\n","               'drop_1_rate' : [0.14],\n","               'dense_1_units' : [4000],\n","               'dense_1_activation' : ['relu'],\n","               'optimizer' : [Adam],\n","               'learning_rate': [1e-05],\n","               'loss_function' : [MeanAbsoluteError],\n","               'epochs' : [2],\n","               'batch_size' : [16, 32]\n","                }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hzbaJgmRyn32"},"source":["# RANDOMNESS ARGUMENTS\n","random_method = 'quantum'\n","\n","# LIMITER ARGUMENTS\n","performance_target = None #None or list [metric, threshold, loss or not] \n","fraction_limit = None #float\n","round_limit = None #int\n","time_limit = '2021-02-25 18:00' #Format \"%Y-%m-%d %H:%M\". CET -4\n","\n","# OPTIMIZER ARGUMENTS\n","reduction_method = 'correlation'\n","reduction_interval = 30\n","reduction_window = 20\n","reduction_threshold = 0.2\n","\n","hyperopt.scan_parameter_space(test_params,\n","                              random_method = random_method,\n","                              seed = seed, \n","                              performance_target = performance_target,\n","                              fraction_limit = fraction_limit,\n","                              round_limit = round_limit,\n","                              time_limit = time_limit,\n","                              reduction_method = reduction_method,\n","                              reduction_interval = reduction_interval,\n","                              reduction_window = reduction_window,\n","                              reduction_threshold = reduction_threshold)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iZrJQkasLeWW"},"source":["### Analysis of scan results"]},{"cell_type":"code","metadata":{"id":"7DyyyugzMDOL"},"source":["hyperopt.initialize_analyzer()\n","\n","# Show the df with the best parameters highlighted.\n","def _highlight_best(row):\n","    if row['val_loss'] == hyperopt.analyzer._minimum_value('val_loss'):\n","        return ['background-color: yellow']*hyperopt.analyzer.df.shape[1]\n","    else:\n","        return ['background-color: white']*hyperopt.analyzer.df.shape[1]\n","    \n","hyperopt.analyzer.df.style.apply(_highlight_best, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HO5idq1OiDl2"},"source":["#### Line plot of a chosen metric"]},{"cell_type":"code","metadata":{"id":"6276FEyTQpZH"},"source":["line_data = hyperopt.analyzer.create_line_data(metric = 'val_loss')\n","line_plot = opt.LinePlot(line_data)\n","line_plot.plot() \n","line_plot.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IJygkk6GiNEU"},"source":["#### Histogram of a metric across all rounds"]},{"cell_type":"code","metadata":{"id":"wfdGEEuShr-Y"},"source":["hist_data = hyperopt.analyzer.create_hist_data(metric = 'val_loss')\n","hist_plot = opt.HistPlot(hist_data)\n","hist_plot.plot() \n","hist_plot.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zeVhQp_ojGM5"},"source":["#### Correlation matrix"]},{"cell_type":"code","metadata":{"id":"JlsSqGBQikqj"},"source":["corr_data = hyperopt.analyzer.correlate(metric = 'val_loss')\n","corr_plot = opt.CorrPlot(corr_data)\n","corr_plot.plot() \n","corr_plot.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Aaymohl3jhvi"},"source":["#### Kernel density estimator plot for one metric"]},{"cell_type":"code","metadata":{"id":"3jHo0Mkhnp07"},"source":["x_kde_1 = 'val_loss'\n","\n","kde_data_1 = hyperopt.analyzer.create_kde_data(x_kde_1)\n","kde_plot_1 = opt.KDEPlot(data = kde_data_1,\n","                         x = x_kde_1)\n","kde_plot_1.plot()\n","kde_plot_1.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wXNFdUXAyzBe"},"source":["#### Kernel density estimator plot for two metrics"]},{"cell_type":"code","metadata":{"id":"wB-CZqg3yzBf"},"source":["x_kde_2 = 'val_loss'\n","y_kde_2 = 'loss'\n","\n","kde_data_2 = hyperopt.analyzer.create_kde_data(x_kde_2,y_kde_2)\n","kde_plot_2 = opt.KDEPlot(data = kde_data_2,\n","                              x = x_kde_2,\n","                              y = y_kde_2)\n","kde_plot_2.plot()\n","kde_plot_2.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dxl_f1QFnynj"},"source":["#### Bar plot with four parameters"]},{"cell_type":"code","metadata":{"id":"N1r7h8A5s_dp"},"source":["x_bar = 'learning_rate'\n","y_bar = 'val_loss'\n","hue_bar = 'conv_3_filters'\n","col_bar = 'dense_1_units'\n","\n","#drop_1_rate, , conv_3_kernel_size, dense_1_units\n","\n","bar_data = hyperopt.analyzer.create_bar_data(x_bar, y_bar, hue_bar, col_bar)\n","bar_plot = opt.BarPlot(bar_data,\n","                       x_bar,\n","                       y_bar,\n","                       hue_bar,\n","                       col_bar)\n","bar_plot.plot()\n","bar_plot.to_file(hyperopt.fig_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x2tfNWsYLk7G"},"source":["## Training and testing of best model from parameter space"]},{"cell_type":"markdown","metadata":{"id":"5AwKLBm_vgc0"},"source":["### Load the model with the best performance"]},{"cell_type":"code","metadata":{"id":"FHSabg0nvbXZ"},"source":["metric = 'val_loss'\n","best_params = hyperopt.get_best_params(metric = metric)\n","hyperopt.load_model_from_scans(best = True, metric = metric)\n","# Plot summary and save model plot.\n","hyperopt.clf.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIGFIP8Rq7D8"},"source":["hyperopt.clf.datahandler.batch_size = hyperopt.best_params['batch_size']\n","hyperopt.clf.datahandler.epochs = hyperopt.best_params['epochs']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jnAnvSXLLwGQ"},"source":["### Train with best parameters"]},{"cell_type":"code","metadata":{"id":"4g_QmUYG5fuT"},"source":["epochs = 25 #hyperopt.best_params['epochs']\n","batch_size = int(hyperopt.best_params['batch_size'])\n","\n","hist = hyperopt.clf.train(checkpoint = True,\n","                          early_stopping = False,\n","                          tb_log = True, \n","                          csv_log = True,\n","                          hyperparam_log = True,\n","                          epochs = epochs, \n","                          batch_size = batch_size,\n","                          verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J9uYqsMlLwGJ"},"source":["### Plot loss after training"]},{"cell_type":"code","metadata":{"id":"Ffr2nfZy5nYi"},"source":["graph = clfutils.TrainingGraphs(hyperopt.clf.logging.history, \n","                                hyperopt.clf.logging.fig_dir)\n","graph.plot_loss(to_file=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-E7qD45fRmd"},"source":["### Evaluate on test data"]},{"cell_type":"code","metadata":{"id":"yWLb5bDNfRme"},"source":["test_loss = hyperopt.clf.evaluate()\n","print('Test loss: ' + str(test_loss))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2uCoVCI-LwGY"},"source":["###  Predict on train and test data"]},{"cell_type":"code","metadata":{"id":"ezklX5YY5fyr"},"source":["pred_train, pred_test = hyperopt.clf.predict()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X_RtwSHpTJ42"},"source":["###  Save the best model"]},{"cell_type":"code","metadata":{"id":"5Lt9sk16WxFr"},"source":["#hyperopt.clf.save_model()\n","hyperopt.clf.pickle_results()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2lHhp6mJWMCp"},"source":["### Show some predictions"]},{"cell_type":"markdown","metadata":{"id":"WS341q-SWMCp"},"source":["#### 10 random training samples"]},{"cell_type":"code","metadata":{"id":"KtpMNRX6WMCp"},"source":["hyperopt.clf.plot_random(no_of_spectra = 10, dataset = 'train', with_prediction = True)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P08GDsllWMCp"},"source":["#### 10 random test samples"]},{"cell_type":"code","metadata":{"id":"PXaoPd3gWMCq"},"source":["hyperopt.clf.plot_random(no_of_spectra = 10, dataset = 'test', with_prediction = True)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZuYfPhUIOTO"},"source":["## Prepare website upload"]},{"cell_type":"code","metadata":{"id":"83dFzkLu3tkL"},"source":["from xpsdeeplearning.network.prepare_upload import Uploader\n","\n","dataset_path = hyperopt.clf.logging.hyperparams[\"input_filepath\"].rsplit(\".\",1)[0] + \"_metadata.json\"\n","uploader = Uploader(hyperopt.clf.logging.root_dir, dataset_path)\n","uploader.prepare_upload_params()\n","uploader.save_upload_params()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pk-dt26OLwHE"},"source":["## Save output of notebook"]},{"cell_type":"code","metadata":{"id":"mkSdyElDLwHF"},"source":["from IPython.display import Javascript, display\n","from nbconvert import HTMLExporter\n","\n","def save_notebook():\n","    display(Javascript(\"IPython.notebook.save_notebook()\"),\n","            include=['application/javascript'])\n","\n","def output_HTML(read_file, output_file):\n","    import codecs\n","    import nbformat\n","    exporter = HTMLExporter()\n","    # read_file is '.ipynb', output_file is '.html'\n","    output_notebook = nbformat.read(read_file, as_version=4)\n","    output, resources = exporter.from_notebook_node(output_notebook)\n","    codecs.open(output_file, 'w', encoding='utf-8').write(output)\n","\n","import time\n","time.sleep(30)\n","save_notebook()\n","print('Notebook saved!')\n","time.sleep(30)\n","current_file = '/content/drive/My Drive/app/xpsdeeplearning/notebooks/talos_optimization.ipynb'\n","output_file = os.path.join(hyperopt.clf.log_dir,'talos_optimization_out.html')\n","output_HTML(current_file, output_file)\n","print('HTML file saved!')"],"execution_count":null,"outputs":[]}]}