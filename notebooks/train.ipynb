{"cells":[{"cell_type":"markdown","metadata":{"id":"vt5hanGL4WpD"},"source":["# Train a deep CNN on XPS data on Google Colab"]},{"cell_type":"markdown","metadata":{"id":"uTjEnuR-LwEo"},"source":["In this notebook, we will train a deep convolutional network on XPS spectra made up of linear combinations of reference spectra."]},{"cell_type":"markdown","metadata":{"id":"u6EVGrGFLwEr"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"dU2aEkqdLwE_"},"source":["### Mount google drive, change working directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5iL11_yXLwFB"},"outputs":[],"source":["# Mount drive\n","from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","\n","# Change working path\n","os.chdir('/content/drive/My Drive/deepxps')"]},{"cell_type":"markdown","metadata":{"id":"rC3yXYXaLwEt"},"source":["### Install packages and import modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4MxYB_b33V9"},"outputs":[],"source":["%%capture\n","# Install packages\n","!pip install python-docx\n","\n","# Import standard modules and magic commands\n","import datetime\n","import numpy as np\n","import pytz\n","import importlib\n","\n","# Set random seed for reproducible loading\n","np.random.seed(502)\n","\n","# Magic commands\n","%matplotlib inline\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""]},{"cell_type":"markdown","metadata":{"id":"ad6lrbtPUwVk"},"source":["### Install and import TensorFlow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1wemeM47_Dsy"},"outputs":[],"source":["# Disable tf warnings\n","os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"BwbL3IE0cm1q"},"source":["### Set seeds and restart session to ensure reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CONzBVbXcm1r"},"outputs":[],"source":["def reset_seeds_and_session(seed=1):\n","   os.environ['PYTHONHASHSEED']=str(seed)\n","   tf.random.set_seed(seed)\n","   np.random.seed(seed)\n","\n","   session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n","                                           inter_op_parallelism_threads=1)\n","   sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(),\n","                               config=session_conf)\n","   tf.compat.v1.keras.backend.set_session(sess) \n","\n","reset_seeds_and_session(seed=1)"]},{"cell_type":"markdown","metadata":{"id":"6kVuecHPLGnN"},"source":["### Check TensorFlow version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_jKIfuFLGnO"},"outputs":[],"source":["f\"TF version: {tf.__version__}.\""]},{"cell_type":"markdown","metadata":{"id":"rMuIKSLjUeBO"},"source":["### Check hardware connection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2wcWtXa1UcSP"},"outputs":[],"source":["from tensorflow.python.profiler import profiler_client\n","\n","if tf.test.gpu_device_name():\n","    print(f\"Found GPU: {tf.test.gpu_device_name()}.\")\n","    !nvidia-smi\n","else:\n","    print(\"Found no GPU.\")\n","try:\n","    tpu_profile_service_address = os.environ['COLAB_TPU_ADDR'].replace('8470', '8466')\n","    print(f\"Found TPU: {profiler_client.monitor(tpu_profile_service_address, 100, 2)}.\")\n","except:\n","    print(\"Found no TPU.\")"]},{"cell_type":"markdown","metadata":{"id":"R1BPxWcLLwFp"},"source":["## Initial training"]},{"cell_type":"markdown","metadata":{"id":"-qQx0QfuLwFQ"},"source":["### Load custom modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfLJzbL04VZ8"},"outputs":[],"source":["try:\n","    importlib.reload(classifier)\n","    importlib.reload(clfutils)\n","    print('Modules were reloaded.')\n","except:\n","    import xpsdeeplearning.network.classifier as classifier\n","    import xpsdeeplearning.network.utils as clfutils\n","    print('Modules were loaded.')"]},{"cell_type":"markdown","metadata":{"id":"j7M70DZczykg"},"source":["### Set up the parameters & folder structure\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXy2WdXYXcXc"},"outputs":[],"source":["time = datetime.datetime.now().astimezone(pytz.timezone('Europe/Berlin')).strftime(\"%Y%m%d_%Hh%Mm\")\n","exp_name = \"Co_linear_combination_normalized_inputs_big_gas_phase\"\n","\n","clf = classifier.Classifier(time = time,\n","                            exp_name = exp_name,\n","                            task = \"regression\",\n","                            intensity_only = True)\n","\n","### If labels not saved with data ###\n","# =============================================================================\n","# labels = ['Fe metal', 'FeO', 'Fe3O4', 'Fe2O3']\n","# clf = classifier.Classifier(time = time,\n","#                            exp_name = exp_name,\n","#                            task = 'regression',\n","#                            intensity_only = True,\n","#                            labels = labels)\n","# ============================================================================="]},{"cell_type":"markdown","metadata":{"id":"q0wkRVOuLwFy"},"source":["### Load and inspect the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZIiyOyKtxmf"},"outputs":[],"source":["input_filepath = r'/content/drive/My Drive/deepxps/datasets/20220704_Co_linear_combination_big_gas_phase.h5'\n","\n","train_test_split = 0.2\n","train_val_split = 0.2\n","no_of_examples = 200000\n","\n","X_train, X_val, X_test, y_train, y_val, y_test,\\\n","    aug_values_train, aug_values_val, aug_values_test =\\\n","        clf.load_data_preprocess(input_filepath = input_filepath,\n","                                 no_of_examples = no_of_examples,\n","                                 train_test_split = train_test_split,\n","                                 train_val_split = train_val_split)\n","               \n","# Check how the examples are distributed across the classes.\n","class_distribution = clf.datahandler.check_class_distribution(clf.task)\n","clf.plot_class_distribution()\n","clf.plot_random(no_of_spectra = 10, dataset = 'train')  "]},{"cell_type":"markdown","metadata":{"id":"TKXmi1LMLwF6"},"source":["### Design the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pyxJ9_qh5awz"},"outputs":[],"source":["try:\n","    importlib.reload(models)\n","    print('Models module was reloaded.')\n","except:\n","    import xpsdeeplearning.network.models as models\n","    print('Models module was loaded.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVvRM4A1xZcL"},"outputs":[],"source":["from tensorflow.keras import layers\n","from tensorflow.keras.initializers import glorot_uniform\n","from tensorflow.python.keras import backend as K\n","\n","class CNN(models.EmptyModel):\n","    \"\"\"\n","    A CNN with three convolutional layers of different kernel size at \n","    the beginning. Works well for learning across scales.\n","    \n","    \"\"\"\n","    def __init__(\n","        self, \n","        inputshape,\n","        num_classes,\n","        task,\n","        ):   \n","        if len(inputshape) == 2:\n","            conv_layer = layers.Conv1D\n","            strides = 1\n","            average_pool_layer = layers.AveragePooling1D\n","        elif len(inputshape) == 3:\n","            conv_layer = layers.Conv2D\n","            strides = (1,1)\n","            average_pool_layer =  layers.AveragePooling2D\n","\n","        if (task == \"regression\" or task == \"multi_class_detection\"):\n","            if num_classes == 1:\n","                output_act = None\n","            else:\n","                output_act = \"sigmoid\"\n","    \n","        elif task == \"classification\":\n","            output_act = \"softmax\"\n","        \n","        self.input_1 = layers.Input(\n","            shape = inputshape,\n","            name=\"input_1\")\n","        self.conv_1_short = conv_layer(\n","            filters=12,\n","            kernel_size=5,\n","            strides=strides,\n","            padding='same',\n","            activation='relu',\n","            name='conv_1_short')(self.input_1)\n","        self.conv_1_medium = conv_layer(\n","            filters=12,\n","            kernel_size=10,\n","            strides=strides,\n","            padding='same',\n","            activation='relu',\n","            name='conv_1_medium')(self.input_1)\n","        self.conv_1_long = conv_layer(\n","            filters=12,\n","            kernel_size=15,\n","            strides=strides,\n","            padding='same',\n","            activation='relu',\n","            name='conv_1_long')(self.input_1)\n","        \n","        sublayers = [self.conv_1_short, self.conv_1_medium, self.conv_1_long]\n","        merged_sublayers = layers.concatenate(sublayers)\n","\n","        self.conv_2 = conv_layer(\n","            filters=10,\n","            kernel_size=5,\n","            strides=strides,\n","            padding='valid',\n","            activation='relu',\n","            name='conv_2')(merged_sublayers)\n","        self.conv_3 = conv_layer(\n","            filters=10,\n","            kernel_size=5,\n","            strides=strides,\n","            padding='valid',\n","            activation='relu',\n","            name=\"conv_3\")(self.conv_2)\n","        self.average_pool_1 = average_pool_layer(\n","            name='average_pool_1')(self.conv_3)\n","        self.flatten_1 = layers.Flatten(\n","            name='flatten1')(self.average_pool_1)\n","        self.drop_1 = layers.Dropout(\n","            rate=0.2,\n","            name='drop_1')(self.flatten_1)\n","        self.dense_1 = layers.Dense(\n","            units=4000,\n","            activation='relu',\n","            name='dense_1')(self.flatten_1)    \n","        self.dense_2 = layers.Dense(\n","            units=num_classes,\n","            activation=output_act,\n","            name='dense_2')(self.dense_1)\n","              \n","        if task == \"regression\":\n","            self.outputs = layers.Lambda(\n","                lambda x: x/tf.reshape(K.sum(x, axis=-1),(-1,1)),\n","                name = 'output_normalization')(self.dense_2)\n","        \n","        else:\n","            self.outputs = self.dense_2\n","\n","        no_of_inputs = len(sublayers)\n","\n","        super(CNN, self).__init__(\n","            inputs=self.input_1,\n","            outputs=self.outputs,\n","            inputshape=inputshape,\n","            num_classes=num_classes,\n","            no_of_inputs=no_of_inputs,\n","            name='CNN')"]},{"cell_type":"markdown","metadata":{"id":"76OKygMa9Xr9"},"source":["#### Build the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Af3wbjEW9Xr-"},"outputs":[],"source":["clf.model = CNN(clf.datahandler.input_shape,\n","                clf.datahandler.num_classes,\n","                task=clf.task)\n","\n","# =============================================================================\n","# clf.model = ResNet1D(clf.datahandler.input_shape,\n","#                      clf.datahandler.num_classess,\n","#                      ap=True)\n","# =============================================================================\n","\n","# Alternative: Build model from available models in models.py\n","# =============================================================================\n","# clf.model = models.RegressionCNN(clf.datahandler.input_shape, \n","#                                  clf.datahandler.num_classes)\n","# =============================================================================\n","# =============================================================================\n","# clf.model = models.ResNet1D(clf.datahandler.input_shape,\n","#                             clf.datahandler.num_classes,\n","#                             ap=True)\n","# =============================================================================\n","# =============================================================================\n","# clf.model = models.ResNet1D(clf.datahandler.input_shape,\n","#                             clf.datahandler.num_classes,\n","#                             ap=True)\n","# ============================================================================="]},{"cell_type":"markdown","metadata":{"id":"I2SpBC-R9XsA"},"source":["### Compile and summarize the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKQZDayn9XsB"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError, CategoricalCrossentropy, BinaryCrossentropy\n","from tensorflow.keras.metrics import MeanSquaredError, CategoricalCrossentropy, BinaryAccuracy\n","    \n","\n","learning_rate = 1e-05 #3e-04\n","optimizer = Adam(learning_rate = learning_rate) \n","\n","if clf.task == \"regression\":\n","    loss = MeanAbsoluteError()\n","    #loss = MeanSquaredError()\n","    metrics=[MeanSquaredError(name=\"mse\")]\n","    \n","elif clf.task == \"classification\":\n","    loss = CategoricalCrossentropy()\n","    metrics = [CategoricalCrossentropy(name=\"accuracy\")]\n","    \n","elif clf.task == \"multi_class_detection\":\n","    loss = BinaryCrossentropy()\n","    metrics = metrics = [BinaryAccuracy(name=\"accuracy\")]\n","    \n","clf.model.compile(loss=loss,\n","                  optimizer=optimizer,\n","                  metrics=metrics)\n","\n","# Plot summary and save model plot.\n","clf.summary()\n","clf.save_and_print_model_image()"]},{"cell_type":"markdown","metadata":{"id":"oeboNYkNsf7Z"},"source":["### Show initial predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tpj40ttsCpEj"},"outputs":[],"source":["pred_train_initial, pred_test_initial = clf.predict()\n","\n","print('Train:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_train[i],3)),\n","          'pred: ' + str(pred_train_initial[i]))\n","print('Test:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_test[i],3)),\n","          'pred: ' + str(pred_test_initial[i]))"]},{"cell_type":"markdown","metadata":{"id":"GDOgVS_bLwGC"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abV_fFCb5fiZ"},"outputs":[],"source":["epochs = 500\n","batch_size = 32\n","\n","hist = clf.train(checkpoint = True,\n","                 early_stopping = False,\n","                 tb_log = True, \n","                 csv_log = True,\n","                 hyperparam_log = True,\n","                 epochs = epochs, \n","                 batch_size = batch_size,\n","                 verbose = 1)\n","\n","sound = False\n","if sound:\n","    from google.colab import output\n","    output.eval_js('new Audio(\"http://soundbible.com/grab.php?id=1795&type=mp3\").play()')"]},{"cell_type":"markdown","metadata":{"id":"J9uYqsMlLwGJ"},"source":["### Plot loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ffr2nfZy5nYi"},"outputs":[],"source":["graph = clfutils.TrainingGraphs(clf.logging.history, clf.logging.fig_dir)\n","graph.plot_loss(to_file = True)\n","if clf.task != \"regression\":\n","    graph.plot_accuracy(to_file = False)"]},{"cell_type":"markdown","metadata":{"id":"jnAnvSXLLwGQ"},"source":["### Evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4g_QmUYG5fuT","scrolled":true},"outputs":[],"source":["if clf.task == 'regression':\n","    test_loss = clf.evaluate()\n","    print('Test loss: ' + str(np.round(test_loss, decimals=8)))\n","\n","else:\n","    score = clf.evaluate()\n","    test_loss, test_accuracy = score[0], score[1]\n","    print('Test loss: ' + str(np.round(test_loss, decimals=8)))\n","    print('Test accuracy: ' + str(np.round(test_accuracy, decimals=3)))"]},{"cell_type":"markdown","metadata":{"id":"2uCoVCI-LwGY"},"source":["###  Predict on train and test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezklX5YY5fyr"},"outputs":[],"source":["pred_train, pred_test = clf.predict()\n","if clf.task != \"regression\":\n","    pred_train_classes, pred_test_classes = clf.predict_classes()\n","\n","print('Train:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_train[i],3)),\n","          'pred: ' + str(pred_train[i]))\n","print('Test:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_test[i],3)),\n","          'pred: ' + str(pred_test[i]))"]},{"cell_type":"markdown","metadata":{"id":"nWbogghiLwGl"},"source":["### Show some predictions"]},{"cell_type":"markdown","metadata":{"id":"T5DGB_OGLwGm"},"source":["#### 10 random training samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"keDKIJriLwGn"},"outputs":[],"source":["clf.plot_random(no_of_spectra = 10, dataset = 'train', with_prediction = True)  "]},{"cell_type":"markdown","metadata":{"id":"-PHAS9XILwGr"},"source":["#### 10 random test samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HM3ZZf-qLwGs"},"outputs":[],"source":["clf.plot_random(no_of_spectra = 10, dataset = 'test', with_prediction = True)  "]},{"cell_type":"markdown","metadata":{"id":"ROK1zo8xzBZF"},"source":["### Show wrong/worst predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"both","id":"uHFC5PWQzE19"},"outputs":[],"source":["if clf.task == 'classification':\n","    clf.show_wrong_classification()\n","else:\n","    clf.show_worst_predictions(no_of_spectra = 20)  "]},{"cell_type":"markdown","metadata":{"id":"KwrgvaLpLwG3"},"source":["### Save model and results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2HBdnZSq5f2D"},"outputs":[],"source":["#clf.save_model()\n","clf.pickle_results()"]},{"cell_type":"markdown","metadata":{"id":"c6B2wITlLwG_"},"source":["### Generate report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rPXD0ki5pOp"},"outputs":[],"source":["dir_name = clf.time + '_' + clf.exp_name\n","rep = clfutils.Report(dir_name)  \n","rep.write()"]},{"cell_type":"markdown","metadata":{"id":"K4mJKWJxWllD"},"source":["## Continue training"]},{"cell_type":"markdown","metadata":{"id":"VH95P7yXcCTq"},"source":["### Load custom modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILECvnh6cCTr"},"outputs":[],"source":["try:\n","    import importlib\n","    importlib.reload(classifier)\n","    importlib.reload(clfutils)\n","    print('\\n Modules were reloaded.')\n","except:\n","    import xpsdeeplearning.network.classifier as classifier\n","    import xpsdeeplearning.network.utils as clfutils\n","    print('\\n Modules were loaded.')"]},{"cell_type":"markdown","metadata":{"id":"qu-oYRDYv93B"},"source":["### Reload classifier from previous run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fffC8Ch1stjm"},"outputs":[],"source":["runpath = r\"/content/drive/My Drive/deepxps/runs/20220628_08h58m_Co_linear_combination_normalized_inputs_small_gas_phase\"\n","clf = classifier.restore_clf_from_logs(runpath)"]},{"cell_type":"markdown","metadata":{"id":"hO_5SSXX0O7I"},"source":["### Load and inspect the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bXXFcFUCWxFI"},"outputs":[],"source":["X_train, X_val, X_test, y_train, y_val, y_test,\\\n","    aug_values_train, aug_values_val, aug_values_test =\\\n","        clf.load_data_preprocess(\n","            input_filepath = clf.logging.hyperparams['input_filepath'],\n","            no_of_examples = clf.logging.hyperparams['no_of_examples'],\n","            train_test_split = clf.logging.hyperparams['train_test_split'],\n","            train_val_split = clf.logging.hyperparams['train_val_split'])\n","                \n","# Check how the examples are distributed across the classes.\n","class_distribution = clf.datahandler.check_class_distribution(clf.task)\n","clf.plot_class_distribution()\n","clf.plot_random(no_of_spectra = 10, dataset = 'train')  "]},{"cell_type":"markdown","metadata":{"id":"BqJ1CeG1WxFM"},"source":["### Load the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvzitnVNWxFR"},"outputs":[],"source":["from tensorflow.keras import backend as K\n","clf.load_model(compile_model = True)"]},{"cell_type":"markdown","metadata":{"id":"51UVlZILWxFW"},"source":["### Summarize the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KN24emZEWxFW"},"outputs":[],"source":["# Plot summary and save model plot.\n","clf.summary()\n","clf.save_and_print_model_image()"]},{"cell_type":"markdown","metadata":{"id":"hr2aMkdaqg2K"},"source":["### Show predictions with current model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YXWyQ_cHqIJ2"},"outputs":[],"source":["pred_train_intermediate, pred_test_intermediate = clf.predict()\n","\n","print('Train:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_train[i],3)),\n","          'pred: ' + str(pred_train_intermediate[i]))\n","print('Test:')\n","for i in range(5):\n","    print('real: ' + str(np.round(clf.datahandler.y_test[i],3)),\n","          'pred: ' + str(pred_test_intermediate[i]))\n","    \n","clf.plot_random(no_of_spectra=10, dataset='test', with_prediction=True)"]},{"cell_type":"markdown","metadata":{"id":"TcYkliU1WxFa"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVQWFw1yWxFa"},"outputs":[],"source":["epochs = 126\n","\n","#new_learning_rate = 5e-06\n","\n","hist = clf.train(checkpoint = True,\n","                 early_stopping = False,\n","                 tb_log = True, \n","                 csv_log = True,\n","                 hyperparam_log = True,\n","                 epochs = epochs, \n","                 batch_size = clf.logging.hyperparams['batch_size'],\n","                 verbose = 1,)\n","#                 new_learning_rate = new_learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"Bj9GSu1eXxPs"},"source":["### Show predictions with current model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjayG89tXxP4"},"outputs":[],"source":["pred_train_intermediate, pred_test_intermediate = clf.predict()\n","\n","print('Train:')\n","for i in range(5):\n","    print('real: ' + str(np.round(y_train[i],3)),\n","          'pred: ' + str(pred_train_intermediate[i]))\n","print('Test:')\n","for i in range(5):\n","    print('real: ' + str(np.round(y_test[i],3)),\n","          'pred: ' + str(pred_test_intermediate[i]))\n","    \n","clf.plot_random(no_of_spectra=10, dataset='test', with_prediction=True)"]},{"cell_type":"markdown","metadata":{"id":"YBDYi_5AXxP5"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKBasChTXxP6"},"outputs":[],"source":["epochs = 1000\n","\n","#new_learning_rate = 5e-06\n","\n","hist = clf.train(checkpoint = True,\n","                 early_stopping = False,\n","                 tb_log = True, \n","                 csv_log = True,\n","                 hyperparam_log = True,\n","                 epochs = epochs, \n","                 batch_size = clf.logging.hyperparams['batch_size'],\n","                 verbose = 1,)\n","#                 new_learning_rate = new_learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"VlkNFbYNWxFe"},"source":["### Plot loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9txM4QFyWxFe"},"outputs":[],"source":["graph = clfutils.TrainingGraphs(clf.logging.history, clf.logging.fig_dir)\n","graph.plot_loss(to_file = True)\n","if clf.task != \"regression\":\n","    graph.plot_accuracy(to_file = True)"]},{"cell_type":"markdown","metadata":{"id":"OY7AxjWsWxFg"},"source":["### Evaluate on test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6deyORg8stjo","scrolled":true},"outputs":[],"source":["if clf.task == \"regression\":\n","    test_loss = clf.evaluate()\n","    print('Test loss: ' + str(np.round(test_loss, decimals=8)))\n","    \n","else:\n","    score = clf.evaluate()\n","    test_loss, test_accuracy = score[0], score[1]\n","    print('Test loss: ' + str(np.round(test_loss, decimals=8)))\n","    print('Test accuracy: ' + str(np.round(test_accuracy, decimals=3)))"]},{"cell_type":"markdown","metadata":{"id":"sAlwSDZNstjo"},"source":["###  Predict on train and test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMRf9Yq1stjo"},"outputs":[],"source":["pred_train, pred_test = clf.predict()\n","if clf.task == \"classification\":\n","    pred_train_classes, pred_test_classes = clf.predict_classes()"]},{"cell_type":"markdown","metadata":{"id":"HyWjEwJoWxFk"},"source":["### Show some predictions"]},{"cell_type":"markdown","metadata":{"id":"pV7aAEMQWxFl"},"source":["#### 10 random training samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T6BgD25qWxFl"},"outputs":[],"source":["clf.plot_random(no_of_spectra = 10, dataset = \"train\", with_prediction = True)  "]},{"cell_type":"markdown","metadata":{"id":"18CPy-pqWxFo"},"source":["#### 10 random test samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mlad8aaEWxFo"},"outputs":[],"source":["clf.plot_random(no_of_spectra = 10, dataset = \"test\", with_prediction = True)  "]},{"cell_type":"markdown","metadata":{"id":"1u-ocIdb1_1Z"},"source":["### Show wrong/worst predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cVZwBLK0stjp"},"outputs":[],"source":["if clf.task == 'classification':\n","    clf.show_wrong_classification()\n","else:\n","    clf.show_worst_predictions(no_of_spectra = 20)  "]},{"cell_type":"markdown","metadata":{"id":"PL3Jn60BWxFq"},"source":["### Save model and data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Lt9sk16WxFr"},"outputs":[],"source":["#clf.save_model()\n","clf.pickle_results()"]},{"cell_type":"markdown","metadata":{"id":"nK9TOFCdWxFt"},"source":["### Generate report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKra_-rCWxFt"},"outputs":[],"source":["dir_name = clf.time + '_' + clf.exp_name\n","rep = clfutils.Report(dir_name)  \n","rep.write()"]},{"cell_type":"markdown","metadata":{"id":"jZuYfPhUIOTO"},"source":["## Prepare website upload"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83dFzkLu3tkL"},"outputs":[],"source":["from xpsdeeplearning.network.prepare_upload import Uploader\n","\n","dataset_path = clf.logging.hyperparams[\"input_filepath\"].rsplit(\".\",1)[0] + \"_metadata.json\"\n","uploader = Uploader(clf.logging.root_dir, dataset_path)\n","uploader.prepare_upload_params()\n","uploader.save_upload_params()"]},{"cell_type":"markdown","metadata":{"id":"Pk-dt26OLwHE"},"source":["## Save output of notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkSdyElDLwHF"},"outputs":[],"source":["from IPython.display import Javascript, display\n","from nbconvert import HTMLExporter\n","\n","def save_notebook():\n","    display(Javascript(\"IPython.notebook.save_notebook()\"),\n","            include=['application/javascript'])\n","\n","def output_HTML(read_file, output_file):\n","    import codecs\n","    import nbformat\n","    exporter = HTMLExporter()\n","    # read_file is '.ipynb', output_file is '.html'\n","    output_notebook = nbformat.read(read_file, as_version=4)\n","    output, resources = exporter.from_notebook_node(output_notebook)\n","    codecs.open(output_file, 'w', encoding='utf-8').write(output)\n","\n","import time\n","import os\n","\n","time.sleep(20)\n","save_notebook()\n","print('Notebook saved!')\n","time.sleep(30)\n","current_file = '/content/drive/My Drive/deepxps/xpsdeeplearning/notebooks/train.ipynb'\n","output_file = os.path.join(clf.logging.log_dir,'train_out.html')\n","output_HTML(current_file, output_file)\n","print('HTML file saved!')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}